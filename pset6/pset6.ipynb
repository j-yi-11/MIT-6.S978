{"cells":[{"cell_type":"markdown","metadata":{"id":"4glFUe2R9uRc"},"source":["# **0. Load Preliminary Functions**"]},{"cell_type":"markdown","metadata":{"id":"W37lUOmT9yle"},"source":["# a. Import Libraries and Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-iydqiNU5fGu"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision import datasets\n","from torchvision import models\n","from torchvision import transforms\n","from torch.autograd import Variable\n","from torchvision.utils import make_grid\n","from torchvision.transforms import ToPILImage\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation, PillowWriter\n","from mpl_toolkits.mplot3d import Axes3D\n","from tqdm.notebook import tqdm\n","import numpy as np\n","import pickle\n","import itertools\n","import math\n","from typing import List\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"markdown","metadata":{"id":"Yb2COTm-ocln"},"source":["# b. MNIST Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-J1xVnVE_6Zm"},"outputs":[],"source":["tensor_transform = transforms.Compose([\n","\t\ttransforms.Pad(2),\n","    transforms.ToTensor(),\n","\t\ttransforms.Normalize((0.5,), (0.5)),\n","])\n","\n","batch_size = 256\n","train_dataset = datasets.MNIST(root = \"./data\",\n","\t\t\t\t\t\t\t\t\ttrain = True,\n","\t\t\t\t\t\t\t\t\tdownload = True,\n","\t\t\t\t\t\t\t\t\ttransform = tensor_transform)\n","test_dataset = datasets.MNIST(root = \"./data\",\n","\t\t\t\t\t\t\t\t\ttrain = False,\n","\t\t\t\t\t\t\t\t\tdownload = True,\n","\t\t\t\t\t\t\t\t\ttransform = tensor_transform)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","\t\t\t\t\t\t\t   batch_size = batch_size,\n","\t\t\t\t\t\t\t\t shuffle = True)\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","\t\t\t\t\t\t\t   batch_size = batch_size,\n","\t\t\t\t\t\t\t\t shuffle = False)\n"]},{"cell_type":"markdown","metadata":{"id":"0_5PFYwtohYY"},"source":["# **1. Consistency Model**\n"]},{"cell_type":"code","source":["def kerras_boundaries(sigma, eps, N, T):\n","    return torch.tensor(\n","        [\n","            (eps ** (1 / sigma) + i / (N - 1) * (T ** (1 / sigma) - eps ** (1 / sigma)))\n","            ** sigma\n","            for i in range(N)\n","        ]\n","    )\n","\n","\n","block = lambda ic, oc: nn.Sequential(\n","    nn.GroupNorm(32, num_channels=ic),\n","    nn.SiLU(),\n","    nn.Conv2d(ic, oc, 3, padding=1),\n","    nn.GroupNorm(32, num_channels=oc),\n","    nn.SiLU(),\n","    nn.Conv2d(oc, oc, 3, padding=1),\n",")\n","\n","\n","class ConsistencyModel(nn.Module):\n","    \"\"\"\n","    This is ridiculous Unet structure, hey but it works!\n","    \"\"\"\n","\n","    def __init__(self, n_channel: int, eps: float = 0.002, n_feat: int = 128) -> None:\n","        super(ConsistencyModel, self).__init__()\n","\n","        self.eps = eps\n","\n","        ### UNet\n","        self.freqs = torch.exp(\n","            -math.log(10000) * torch.arange(start=0, end=n_feat, dtype=torch.float32) / n_feat\n","        )\n","\n","        self.down = nn.Sequential(\n","            *[\n","                nn.Conv2d(n_channel, n_feat, 3, padding=1),\n","                block(n_feat, n_feat),\n","                block(n_feat, 2 * n_feat),\n","                block(2 * n_feat, 2 * n_feat),\n","            ]\n","        )\n","\n","        self.time_downs = nn.Sequential(\n","            nn.Linear(2 * n_feat, n_feat),\n","            nn.Linear(2 * n_feat, n_feat),\n","            nn.Linear(2 * n_feat, 2 * n_feat),\n","            nn.Linear(2 * n_feat, 2 * n_feat),\n","        )\n","\n","        self.mid = block(2 * n_feat, 2 * n_feat)\n","\n","        self.up = nn.Sequential(\n","            *[\n","                block(2 * n_feat, 2 * n_feat),\n","                block(2 * 2 * n_feat, n_feat),\n","                block(n_feat, n_feat),\n","                nn.Conv2d(2 * n_feat, 2 * n_feat, 3, padding=1),\n","            ]\n","        )\n","        self.last = nn.Conv2d(2 * n_feat + n_channel, n_channel, 3, padding=1)\n","\n","    def forward(self, x, t) -> torch.Tensor:\n","        if isinstance(t, float):\n","            t = (\n","                torch.tensor([t] * x.shape[0], dtype=torch.float32)\n","                .to(x.device)\n","                .unsqueeze(1)\n","            )\n","\n","        # time embedding\n","        args = t.float() * self.freqs[None].to(t.device)\n","        t_emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1).to(x.device)\n","\n","        x_ori = x\n","\n","        # perform F(x, t)\n","        hs = []\n","        for idx, layer in enumerate(self.down):\n","            if idx % 2 == 1:\n","                x = layer(x) + x\n","            else:\n","                x = layer(x)\n","                x = F.interpolate(x, scale_factor=0.5)\n","                hs.append(x)\n","\n","            x = x + self.time_downs[idx](t_emb)[:, :, None, None]\n","\n","        x = self.mid(x)\n","\n","        for idx, layer in enumerate(self.up):\n","            if idx % 2 == 0:\n","                x = layer(x) + x\n","            else:\n","                x = torch.cat([x, hs.pop()], dim=1)\n","                x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n","                x = layer(x)\n","\n","        x = self.last(torch.cat([x, x_ori], dim=1))\n","\n","        ##################\n","        ### Problem 1 (a)\n","        ##################\n","\n","        return c_skip_t[:, :, None, None] * x_ori + c_out_t[:, :, None, None] * x\n","\n","    def loss(self, x, z, t1, t2, ema_model):\n","        ##################\n","        ### Problem 1 (c)\n","        ##################\n","        return 0.0\n","\n","    @torch.no_grad()\n","    def sample(self, x, ts: List[float]):\n","        ##################\n","        ### Problem 1 (b)\n","        ##################\n","\n","        return x"],"metadata":{"id":"PVVld9phXEO7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# c. Training Functions"],"metadata":{"id":"9-FqJL4a2g32"}},{"cell_type":"code","source":["def train(\n","    n_epoch: int = 100,\n","    n_channels=1,\n","    n_feat = 256\n","):\n","    dataloader = train_loader\n","    model = ConsistencyModel(n_channels, n_feat=n_feat)\n","    model.to(device)\n","    optim = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","\n","    # Define \\theta_{-}, which is EMA of the params\n","    ema_model = ConsistencyModel(n_channels, n_feat=n_feat)\n","    ema_model.to(device)\n","    ema_model.load_state_dict(model.state_dict())\n","\n","    for epoch in range(1, n_epoch):\n","        N = math.ceil(math.sqrt((epoch * (150**2 - 4) / n_epoch) + 4) - 1) + 1\n","        boundaries = kerras_boundaries(7.0, 0.002, N, 80.0).to(device)\n","\n","        pbar = tqdm(dataloader)\n","        loss_ema = None\n","        model.train()\n","        for x, _ in pbar:\n","            optim.zero_grad()\n","            x = x.to(device)\n","\n","            z = torch.randn_like(x)\n","            t = torch.randint(0, N - 1, (x.shape[0], 1), device=device)\n","            t_0 = boundaries[t]\n","            t_1 = boundaries[t + 1]\n","\n","            loss = model.loss(x, z, t_0, t_1, ema_model=ema_model)\n","\n","            loss.backward()\n","            if loss_ema is None:\n","                loss_ema = loss.item()\n","            else:\n","                loss_ema = 0.9 * loss_ema + 0.1 * loss.item()\n","\n","            optim.step()\n","            with torch.no_grad():\n","                mu = math.exp(2 * math.log(0.95) / N)\n","                # update \\theta_{-}\n","                for p, ema_p in zip(model.parameters(), ema_model.parameters()):\n","                    ema_p.mul_(mu).add_(p, alpha=1 - mu)\n","\n","            pbar.set_description(f\"loss: {loss_ema:.10f}, mu: {mu:.10f}\")\n","\n","        model.eval()\n","        with torch.no_grad():\n","            # Sample 5 Steps\n","            xh = model.sample(\n","                torch.randn_like(x).to(device=device) * 80.0,\n","                list(reversed([5.0, 10.0, 20.0, 40.0, 80.0])),\n","            )\n","            xh = (xh * 0.5 + 0.5).clamp(0, 1)\n","            grid = make_grid(xh[:81], nrow=9, padding=0)\n","\n","            img = ToPILImage()(grid)\n","            plt.imshow(img)\n","            plt.show()\n"],"metadata":{"id":"uiOTUyyZaEXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# e. Training\n"],"metadata":{"id":"37zTyd_L2tDB"}},{"cell_type":"code","source":["##################\n","### Problem 1 (d)\n","##################\n","n_epoch = 100\n","n_feat = 256\n","\n","train(n_epoch=n_epoch, n_feat=n_feat)"],"metadata":{"id":"eagIN387u-6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P48jRvRiuqYt"},"source":["# **2. Ablation Study**"]},{"cell_type":"code","source":["##################\n","### Problem 2: Ablation Study\n","##################"],"metadata":{"id":"vwuPl2FQzGJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8oh5ONMYg7lm"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}