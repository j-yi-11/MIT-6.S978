{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **0. Load Preliminary Functions**"],"metadata":{"id":"4glFUe2R9uRc"}},{"cell_type":"markdown","source":["# a. Import Libraries and Functions"],"metadata":{"id":"W37lUOmT9yle"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-iydqiNU5fGu"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision import datasets\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import numpy as np\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device('cpu')\n"]},{"cell_type":"markdown","source":["# b. MNIST Data Loader"],"metadata":{"id":"Yb2COTm-ocln"}},{"cell_type":"code","source":["def binarize_image(tensor):\n","    return (tensor > 0.5).float()\n","\n","tensor_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Lambda(binarize_image)\n","])\n","\n","batch_size = 128\n","train_dataset = datasets.MNIST(root = \"./data\",\n","\t\t\t\t\t\t\t\t\ttrain = True,\n","\t\t\t\t\t\t\t\t\tdownload = True,\n","\t\t\t\t\t\t\t\t\ttransform = tensor_transform)\n","test_dataset = datasets.MNIST(root = \"./data\",\n","\t\t\t\t\t\t\t\t\ttrain = False,\n","\t\t\t\t\t\t\t\t\tdownload = True,\n","\t\t\t\t\t\t\t\t\ttransform = tensor_transform)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","\t\t\t\t\t\t\t   batch_size = batch_size,\n","\t\t\t\t\t\t\t\t shuffle = True)\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","\t\t\t\t\t\t\t   batch_size = batch_size,\n","\t\t\t\t\t\t\t\t shuffle = False)\n"],"metadata":{"id":"-J1xVnVE_6Zm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **1. PixelCNN**\n","\n","\n","# a. Training Function"],"metadata":{"id":"0_5PFYwtohYY"}},{"cell_type":"code","source":["bce = F.binary_cross_entropy\n","\n","def train(dataloader, model, optimizer, epochs):\n","    losses = []\n","\n","    for epoch in tqdm(range(epochs), desc='Epochs'):\n","        running_loss = 0.0\n","        batch_progress = tqdm(dataloader, desc='Batches', leave=False)\n","\n","        for iter, (images, labels) in enumerate(batch_progress):\n","            images = images.to(device)\n","            tgt = images.clone()\n","            pred = model(images)\n","            loss = bce(pred, tgt)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            avg_loss = running_loss * batch_size / len(train_dataset)\n","            losses.append(loss.item())\n","\n","        tqdm.write(f'----\\nEpoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\\n')\n","\n","    return losses\n"],"metadata":{"id":"jDICmZADIiUE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# b. Masked Convolution"],"metadata":{"id":"N0mqbPsCopVJ"}},{"cell_type":"code","source":["class MaskedConv2d(nn.Conv2d):\n","    ##################\n","    ### Problem 2(a): Implement MaskedConv2d\n","    def __init__(self, **args):\n","        pass\n","    def forward(self, x):\n","        pass\n","    ##################\n"],"metadata":{"id":"46O03X-498n0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# c. Model"],"metadata":{"id":"XYUg7AjHottB"}},{"cell_type":"code","source":["class PixelCNN(nn.Module):\n","    ##################\n","    ### Problem 2(b): Implement PixelCNN\n","    def __init__(self):\n","        pass\n","    def forward(self, x):\n","        pass\n","    ##################"],"metadata":{"id":"hrG8n5WJAo51"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# d. Training"],"metadata":{"id":"S2KxDaEBo-9Z"}},{"cell_type":"code","source":["##################\n","### Problem 2(c): Training\n","epochs = 100\n","model = PixelCNN().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","log = train(train_loader, model, optimizer, epochs)\n","##################\n"],"metadata":{"id":"_n_2PGRUAzou"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# e. Evaluation (Reconstruction)"],"metadata":{"id":"TQnZFPm_pDkc"}},{"cell_type":"code","source":["H, W = 28, 28\n","\n","with torch.no_grad():\n","  for iter, (images, labels) in enumerate(test_loader):\n","      images = images.to(device)\n","      pred = model(images)\n","\n","      for i in range(H):\n","          for j in range(W):\n","              pred[:, :, i, j] = torch.bernoulli(pred[:, :, i, j], out=pred[:, :, i, j])\n","      break\n","\n","samples = pred.detach().cpu().numpy().transpose(0, 2, 3, 1)\n","fig, axes = plt.subplots(8, 8, figsize=(15, 15))\n","\n","for i in range(64):\n","    sample = samples[i]\n","    row, col = divmod(i, 8)\n","    axes[row, col].imshow(sample, cmap='gray')\n","    axes[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"VFFyeeEjxsxQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# f. Evaluation (Generation)"],"metadata":{"id":"mqr0yIvYpL2_"}},{"cell_type":"code","source":["samples = torch.zeros(size=(64, 1, H, W)).to(device)\n","with torch.no_grad():\n","    for i in range(H):\n","        for j in range(W):\n","            if j > 0 and i > 0:\n","                out = model(samples)\n","                samples[:, :, i, j] = torch.bernoulli(out[:, :, i, j], out=samples[:, :, i, j])\n","\n","samples = samples.cpu().numpy().transpose(0, 2, 3, 1)\n","fig, axes = plt.subplots(8, 8, figsize=(15, 15))\n","\n","for i in range(64):\n","    sample = samples[i]\n","    row, col = divmod(i, 8)\n","    axes[row, col].imshow(sample, cmap='gray')\n","    axes[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"tQseF8t5BpPU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Conditional PixelCNN**\n","\n","\n","# a. Training Function"],"metadata":{"id":"252Jr5orpZGc"}},{"cell_type":"code","source":["def train_cond(dataloader, model, optimizer, epochs, n_classes):\n","    losses = []\n","\n","    for epoch in tqdm(range(epochs), desc='Epochs'):\n","        running_loss = 0.0\n","        batch_progress = tqdm(dataloader, desc='Batches', leave=False)\n","\n","        for iter, (images, labels) in enumerate(batch_progress):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            tgt = images.clone()\n","            labels = F.one_hot(labels, num_classes=n_classes).float()\n","            pred = model(images, labels)\n","            loss = bce(pred, tgt)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            avg_loss = running_loss * batch_size / len(train_dataset)\n","            losses.append(loss.item())\n","\n","        tqdm.write(f'----\\nEpoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\\n')\n","\n","    return losses"],"metadata":{"id":"fKgicaMje-hL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# b. Conditional Masked Convolution"],"metadata":{"id":"Nh9gGbKUpfFy"}},{"cell_type":"code","source":["class ConditionalMaskedConv2d(MaskedConv2d):\n","    ##################\n","    ### Problem 3(b): Implement ConditionalMaskedConv2d\n","    def __init__(self, **args):\n","        pass\n","    def forward(self, x, class_condition):\n","        pass\n","    ##################"],"metadata":{"id":"YUEQ-RzyHdrs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# c. Model"],"metadata":{"id":"XYhdWZdZpjTy"}},{"cell_type":"code","source":["class ConditionalPixelCNN(nn.Module):\n","    ##################\n","    ### Problem 3(b): Implement ConditionalPixelCNN\n","    def __init__(self, num_classes):\n","        pass\n","    def forward(self, x, class_condition):\n","        pass\n","    ##################"],"metadata":{"id":"sjICYyhWeZUI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# d. Training"],"metadata":{"id":"0V3Skf2mpoN5"}},{"cell_type":"code","source":["##################\n","epochs = 100\n","### Problem 3(c): Training\n","n_classes = 10\n","model = ConditionalPixelCNN(n_classes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","log = train_cond(train_loader, model, optimizer, epochs, n_classes)\n","##################\n"],"metadata":{"id":"dXkK2VKIeo3K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# e. Evaluation (Reconstruction)"],"metadata":{"id":"epotdWhTpo62"}},{"cell_type":"code","source":["H, W = 28, 28\n","\n","with torch.no_grad():\n","  for iter, (images, labels) in enumerate(test_loader):\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      labels = F.one_hot(labels, num_classes=n_classes).float()\n","      pred = model(images, labels)\n","\n","      for i in range(H):\n","          for j in range(W):\n","              pred[:, :, i, j] = torch.bernoulli(pred[:, :, i, j], out=pred[:, :, i, j])\n","      break\n","\n","samples = pred.detach().cpu().numpy().transpose(0, 2, 3, 1)\n","fig, axes = plt.subplots(8, 8, figsize=(15, 15))\n","\n","for i in range(64):\n","    sample = samples[i]\n","    row, col = divmod(i, 8)\n","    axes[row, col].imshow(sample, cmap='gray')\n","    axes[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"KLW9jRCyfiOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# f. Evaluation (Generation)"],"metadata":{"id":"hvOHwS6yptWn"}},{"cell_type":"code","source":["samples = torch.zeros(size=(60, 1, H, W)).to(device)\n","sample_classes = np.sort(np.array([np.arange(n_classes)] * 6).flatten())\n","sample_classes = F.one_hot(torch.tensor(sample_classes), num_classes=n_classes).to(device).float()\n","\n","with torch.no_grad():\n","    for i in range(H):\n","        for j in range(W):\n","            if j > 0 and i > 0:\n","                out = model(samples, sample_classes)\n","                samples[:, :, i, j] = torch.bernoulli(out[:, :, i, j], out=samples[:, :, i, j])\n","\n","samples = samples.cpu().numpy().transpose(0, 2, 3, 1)\n","fig, axes = plt.subplots(10, 6, figsize=(15, 30))\n","\n","for i in range(60):\n","    sample = samples[i]\n","    row, col = divmod(i, 6)\n","    axes[row, col].imshow(sample, cmap='gray')\n","    axes[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"YIGipU7ofRJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NDRSZeovtYa_"},"execution_count":null,"outputs":[]}]}